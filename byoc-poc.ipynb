{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy to BYOC on AKS\n",
    "\n",
    "description: deploy a BYOC container on AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM')"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                                         \n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (2/2)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3                0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3                0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3                0.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.7s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3                0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3                0.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.0s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3                0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3                1.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3                1.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3                1.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.6s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3                1.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3                1.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.9s (8/9)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3                1.6s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 86B                                           0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/library/python:3@sha256:39c16d1a064c0239939d4ed5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] COPY ./src/app.py /usr/local/bin                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/4] COPY ./src/runsvdir /usr/local/bin                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/4] RUN pip install flask                                     0.0s\n",
      "\u001b[0m => exporting to image                                                     0.1s\n",
      "\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.0s (9/9) FINISHED                                                \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3                1.6s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 86B                                           0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/library/python:3@sha256:39c16d1a064c0239939d4ed5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] COPY ./src/app.py /usr/local/bin                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/4] COPY ./src/runsvdir /usr/local/bin                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/4] RUN pip install flask                                     0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.1s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:5203a38a4833707c867b2962421a58194b5b27aed2010  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to inferencepmaef584480.azurecr.io/flaskproject              0.0s\n",
      "\u001b[0m\u001b[?25hUsing default tag: latest\n",
      "The push refers to repository [inferencepmaef584480.azurecr.io/flaskproject]\n",
      "\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[5Blatest: digest: sha256:c414300a25cd2504f834a83a98d181ca05f21de17f18680121f3218296cfe25d size: 2842\n"
     ]
    }
   ],
   "source": [
    "!docker build --tag inferencepmaef584480.azurecr.io/flaskproject:no-entry-chmod .\n",
    "!docker push inferencepmaef584480.azurecr.io/flaskproject:no-entry-chmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ComputeTargetException",
     "evalue": "ComputeTargetException:\n\tMessage: Long running operation information not known, unable to poll. Current state is Succeeded\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Long running operation information not known, unable to poll. Current state is Succeeded\"\n    }\n}",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeTargetException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/azureml/lib/python3.7/site-packages/azureml/core/compute/compute.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0moperation_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Provisioning operation finished, operation \"{}\"'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/azureml/lib/python3.7/site-packages/azureml/core/compute/compute.py\u001b[0m in \u001b[0;36m_wait_for_completion\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_operation_endpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mComputeTargetException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No operation endpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0moperation_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_operation_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mComputeTargetException\u001b[0m: ComputeTargetException:\n\tMessage: No operation endpoint\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"No operation endpoint\"\n    }\n}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mComputeTargetException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4948b18eb53d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAksCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gopalv-byoc-test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/azureml/lib/python3.7/site-packages/azureml/core/compute/compute.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m                 raise ComputeTargetException('Long running operation information not known, unable to poll. '\n\u001b[0;32m--> 539\u001b[0;31m                                              'Current state is {}'.format(self.provisioning_state))\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mComputeTargetException\u001b[0m: ComputeTargetException:\n\tMessage: Long running operation information not known, unable to poll. Current state is Succeeded\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Long running operation information not known, unable to poll. Current state is Succeeded\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AksCompute\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "try:\n",
    "    test = AksCompute.create(workspace=ws, name='gopalv-byoc-test', provisioning_configuration=prov_config)\n",
    "except ComputeTargetException:\n",
    "    test = AksCompute(ws, 'gopalv-byoc-test')\n",
    "\n",
    "test.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy webservice\n",
    "\n",
    "In this case we deploy to the local compute, but for other options, see [our documentation](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where?tabs=azcli).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING - Warning, custom base image or base dockerfile detected without a specified `inferencing_stack_version`. Please set environment.inferencing_stack_version='latest'\n",
      "Running.........\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import InferenceConfig\n",
    "from random import randint\n",
    "from azureml.core.model import Model\n",
    "\n",
    "service_name = \"gopalv-byoc-test-1\"\n",
    "\n",
    "\n",
    "env = Environment(\"byoc-test\")\n",
    "\n",
    "env.docker.base_image = \"inferencepmaef584480.azurecr.io/flaskproject:no-entry-chmod\"\n",
    "\n",
    "# Need these to tell AML not to install our default components\n",
    "env.python.user_managed_dependencies = True\n",
    "env.inferencing_stack_version = None\n",
    "\n",
    "env.environment_variables[\"WORKER_COUNT\"] = \"1\"\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    # this entry script is where we dispatch a call to the Triton server\n",
    "    source_directory=\"src\",\n",
    "    entry_script=\"app.py\",\n",
    "    environment=env,\n",
    ")\n",
    "\n",
    "config = AksWebservice.deploy_configuration(\n",
    "    compute_target_name=\"gopalv-byoc-test\",\n",
    ")\n",
    "\n",
    "service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=service_name,\n",
    "    models=[],\n",
    "    inference_config=inference_config,\n",
    "    deployment_config=config\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_uri = service.scoring_uri[:-5]\n",
    "token = service.get_keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'Hello, world!'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "result = requests.get(url=base_uri, data={\"test\": 0}, headers={\"Authorization\": f\"Bearer {token}\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'triton-densenet-onnx-local79907': AksWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=triton-densenet-onnx-local79907, image_id=None, compute_type=None, state=AKS, scoring_uri=None, tags=http://52.166.71.20:80/api/v1/service/triton-densenet-onnx-local79907/score, properties={}, created_by={'azureml.git.repository_uri': 'git@github.com:Azure/azureml-examples.git', 'mlflow.source.git.repoURL': 'git@github.com:Azure/azureml-examples.git', 'azureml.git.branch': 'ey-hack', 'mlflow.source.git.branch': 'ey-hack', 'azureml.git.commit': 'ae4a3b0ac5a284c9b035b950c7bf01ca152af389', 'mlflow.source.git.commit': 'ae4a3b0ac5a284c9b035b950c7bf01ca152af389', 'azureml.git.dirty': 'True', 'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'triton-densenet-onnx-local75850': AksWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=triton-densenet-onnx-local75850, image_id=None, compute_type=None, state=AKS, scoring_uri=None, tags=http://52.166.71.20:80/api/v1/service/triton-densenet-onnx-local75850/score, properties={}, created_by={'azureml.git.repository_uri': 'git@github.com:Azure/azureml-examples.git', 'mlflow.source.git.repoURL': 'git@github.com:Azure/azureml-examples.git', 'azureml.git.branch': 'ey-hack', 'mlflow.source.git.branch': 'ey-hack', 'azureml.git.commit': 'ae4a3b0ac5a284c9b035b950c7bf01ca152af389', 'mlflow.source.git.commit': 'ae4a3b0ac5a284c9b035b950c7bf01ca152af389', 'azureml.git.dirty': 'True', 'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'aks-service-2': AksWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=aks-service-2, image_id=None, compute_type=None, state=AKS, scoring_uri=None, tags=http://104.40.214.217:80/api/v1/service/aks-service-2/score, properties={}, created_by={'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'triton-webservice': AksWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=triton-webservice, image_id=None, compute_type=None, state=AKS, scoring_uri=None, tags=http://40.118.65.152:80/api/v1/service/triton-webservice/, properties=None, created_by={'azureml.git.repository_uri': 'git@github.com:gvashishtha/Triton-Private-Preview.git', 'mlflow.source.git.repoURL': 'git@github.com:gvashishtha/Triton-Private-Preview.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '01efaf804b39886ebe66fbddc33fbb401eaba542', 'mlflow.source.git.commit': '01efaf804b39886ebe66fbddc33fbb401eaba542', 'azureml.git.dirty': 'True', 'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'aci-service-appinsights': AciWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=aci-service-appinsights, image_id=None, compute_type=None, state=ACI, scoring_uri=None, tags=http://76bc10e6-3b44-40cc-9464-034b59a2ee1e.westeurope.azurecontainer.io/score, properties={'area': 'diabetes', 'type': 'regression'}, created_by={'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'triton-bidaf-9-monitor': AksWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=triton-bidaf-9-monitor, image_id=None, compute_type=None, state=AKS, scoring_uri=None, tags=http://40.118.65.152:80/api/v1/service/triton-bidaf-9-monitor/, properties=None, created_by={'azureml.git.repository_uri': 'git@github.com:gvashishtha/azureml-examples.git', 'mlflow.source.git.repoURL': 'git@github.com:gvashishtha/azureml-examples.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': '170fc9f2ba5987454f5a6c1efee7901acfe5a444', 'mlflow.source.git.commit': '170fc9f2ba5987454f5a6c1efee7901acfe5a444', 'azureml.git.dirty': 'True', 'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'triton-densenet-onnx': AksWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=triton-densenet-onnx, image_id=None, compute_type=None, state=AKS, scoring_uri=None, tags=http://52.175.205.169:80/api/v1/service/triton-densenet-onnx/score, properties={}, created_by={'azureml.git.repository_uri': 'msdata@vs-ssh.visualstudio.com:v3/msdata/Vienna/AzureMlCli', 'mlflow.source.git.repoURL': 'msdata@vs-ssh.visualstudio.com:v3/msdata/Vienna/AzureMlCli', 'azureml.git.branch': 'add-triton-notebook', 'mlflow.source.git.branch': 'add-triton-notebook', 'azureml.git.commit': '468462e1a80bc34725e6d448fa7c0264274f5df6', 'mlflow.source.git.commit': '468462e1a80bc34725e6d448fa7c0264274f5df6', 'azureml.git.dirty': 'True', 'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'retinanet-deploy': AksWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=retinanet-deploy, image_id=None, compute_type=None, state=AKS, scoring_uri=None, tags=http://52.229.63.214:80/api/v1/service/retinanet-deploy/score, properties=None, created_by={'azureml.git.repository_uri': 'git@github.com:gvashishtha/Triton-AML.git', 'mlflow.source.git.repoURL': 'git@github.com:gvashishtha/Triton-AML.git', 'azureml.git.branch': 'gopalv/retinanet', 'mlflow.source.git.branch': 'gopalv/retinanet', 'azureml.git.commit': '43fcc40a1d95b016e9ff6031ebb3f967d402f0c5', 'mlflow.source.git.commit': '43fcc40a1d95b016e9ff6031ebb3f967d402f0c5', 'azureml.git.dirty': 'True', 'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'ncd-triton': AksWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=ncd-triton, image_id=None, compute_type=None, state=AKS, scoring_uri=None, tags=http://40.113.101.136:80/api/v1/service/ncd-triton/, properties={}, created_by={'azureml.git.repository_uri': 'gopalv@vs-ssh.visualstudio.com:v3/dlan/Home/aml-triton', 'mlflow.source.git.repoURL': 'gopalv@vs-ssh.visualstudio.com:v3/dlan/Home/aml-triton', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '4d5a5e8f1fd038f341ec6713b382430e0c78f644', 'mlflow.source.git.commit': '4d5a5e8f1fd038f341ec6713b382430e0c78f644', 'azureml.git.dirty': 'True', 'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'aci-triton-densenet': AciWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=aci-triton-densenet, image_id=None, compute_type=None, state=ACI, scoring_uri=None, tags=http://3bc0b85f-c903-442f-9c15-5151e9deb246.westeurope.azurecontainer.io/score, properties={}, created_by={'azureml.git.repository_uri': 'git@github.com:gvashishtha/Triton-AML.git', 'mlflow.source.git.repoURL': 'git@github.com:gvashishtha/Triton-AML.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': 'd577f93c124e4c301c5a10beab972067a602b31f', 'mlflow.source.git.commit': 'd577f93c124e4c301c5a10beab972067a602b31f', 'azureml.git.dirty': 'True', 'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'aci-densenet-onnx': AciWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=aci-densenet-onnx, image_id=None, compute_type=None, state=ACI, scoring_uri=None, tags=http://cc7ecd1f-40d9-4735-b42b-13bfbddd4c52.westeurope.azurecontainer.io/score, properties={}, created_by={'azureml.git.repository_uri': 'git@github.com:gvashishtha/Triton-AML.git', 'mlflow.source.git.repoURL': 'git@github.com:gvashishtha/Triton-AML.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.dirty': 'True', 'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'gpu-densenet-onnx': AksWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=gpu-densenet-onnx, image_id=None, compute_type=None, state=AKS, scoring_uri=None, tags=http://40.65.113.227:80/api/v1/service/gpu-densenet-onnx/score, properties={}, created_by={'azureml.git.repository_uri': 'https://github.com/omnipo/MachineLearningNotebooks.git', 'mlflow.source.git.repoURL': 'https://github.com/omnipo/MachineLearningNotebooks.git', 'azureml.git.branch': 'gopalv/refactor', 'mlflow.source.git.branch': 'gopalv/refactor', 'azureml.git.commit': 'a26f513ed2593c239bb05f50099e413ff770874d', 'mlflow.source.git.commit': 'a26f513ed2593c239bb05f50099e413ff770874d', 'azureml.git.dirty': 'True', 'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'gopalv-automl-failure': AciWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=gopalv-automl-failure, image_id=None, compute_type=None, state=ACI, scoring_uri=None, tags=None, properties={}, created_by={'runId': 'AutoML_68bdc093-0a17-47e7-925c-2689fe3eb148_1', 'hasInferenceSchema': 'False', 'hasHttps': 'False'}), 'sample-2-regression---automobile': AksWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=sample-2-regression---automobile, image_id=None, compute_type=None, state=AKS, scoring_uri=None, tags=http://40.113.101.136:80/api/v1/service/sample-2-regression---automobile/score, properties={'CreatedByAMLStudio': 'true'}, created_by={'LinkedPipelineDraftId': 'b48ce5c7-c484-4813-96f1-fa5f52a3e2ad', 'LinkedPipelineRunId': '7d735395-42c9-47a7-b28c-29cdf4fd9597', 'hasInferenceSchema': 'True', 'hasHttps': 'False'}), 'gopalv-test-aci2': AciWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=gopalv-test-aci2, image_id=None, compute_type=None, state=ACI, scoring_uri=None, tags=http://6bab3539-a730-451c-89be-6350a15264fb.westeurope.azurecontainer.io/score, properties={}, created_by={'runId': 'AutoML_68bdc093-0a17-47e7-925c-2689fe3eb148_1', 'hasInferenceSchema': 'True', 'hasHttps': 'False'}), 'gopalv-automl-aci': AciWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=gopalv-automl-aci, image_id=None, compute_type=None, state=ACI, scoring_uri=None, tags=http://accdf0a4-78c0-4f14-810a-9c8eab4c880f.westeurope.azurecontainer.io/score, properties={}, created_by={'runId': 'AutoML_68bdc093-0a17-47e7-925c-2689fe3eb148_1', 'hasInferenceSchema': 'True', 'hasHttps': 'False'}), 'gopalv-automl-test': AksWebservice(workspace=Workspace.create(name='Inference-PM-AML-Workspace', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='Inference-PM'), name=gopalv-automl-test, image_id=None, compute_type=None, state=AKS, scoring_uri=None, tags=http://40.113.101.136:80/api/v1/service/gopalv-automl-test/score, properties={}, created_by={'runId': 'AutoML_68bdc093-0a17-47e7-925c-2689fe3eb148_1', 'hasInferenceSchema': 'True', 'hasHttps': 'False'})}\n"
     ]
    }
   ],
   "source": [
    "print(ws.webservices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = AksWebservice(ws, \"gopalv-byoc-test-1\")\n",
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('azureml': conda)",
   "metadata": {
    "interpreter": {
     "hash": "53514593536e52de022f29ef618678eddccd581b6db5dc532e9838fb19203af5"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "name": "deploy-densenet-local",
  "task": "Use the high-performance Triton Inference Server with Azure Machine Learning"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}